{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#instalacion de dependecias"
      ],
      "metadata": {
        "id": "iCbI2uojOUWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dipy"
      ],
      "metadata": {
        "id": "MuukkOzWr0eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "P5_2P5e_agTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from tensorflow.keras.layers  import Add\n",
        "from skimage.transform import rescale, resize, downscale_local_mean\n",
        "from keras.layers import Input, Activation\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras import losses\n",
        "\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import cv2\n",
        "import time\n",
        "from tensorflow.keras.models import load_model\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from dipy.io.gradients import read_bvals_bvecs\n",
        "from dipy.core.gradients import gradient_table\n",
        "import dipy.reconst.dti as dti\n",
        "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
        "from dipy.reconst.dti import fractional_anisotropy, color_fa\n",
        "import dipy.data as dpd"
      ],
      "metadata": {
        "id": "gUU7fX6su206"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_results_3_images(lowres, preds, highres):\n",
        "  \"\"\"\n",
        "  mostrar las 3 imagenes(lowres, preds, highres)\n",
        "  \"\"\"\n",
        "  i = 0\n",
        "  fig, axes = plt.subplots(1, 3, figsize=(25,25))\n",
        "  plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
        "  ax1, ax2, ax3 = axes\n",
        "  ax1.imshow(lowres)\n",
        "  ax1.set_title('lowres')\n",
        "  ax2.imshow(preds)\n",
        "  ax2.set_title('prediction')\n",
        "  ax3.imshow(highres)\n",
        "  ax3.set_title('highres')"
      ],
      "metadata": {
        "id": "z7Zu8lPlvcrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbZTzv-PrVuj"
      },
      "outputs": [],
      "source": [
        "#recurso: https://github.com/Likarian/VDSR-keras/tree/14a6bf94c7d23f197bcf0a18353bdcb4c7e3bd8c\n",
        "def VDSR_origin(input_shape):\n",
        "    low_resolution_image = Input(shape = input_shape )\n",
        "    processing = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', activation='relu')(low_resolution_image)    \n",
        "    processing = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', activation='relu')(processing)\n",
        "    processing = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', activation='relu')(processing)\n",
        "    processing = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', activation='relu')(processing)\n",
        "    processing = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', activation='relu')(processing)\n",
        "    processing = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', activation='relu')(processing)\n",
        "    processing = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', activation='relu')(processing)\n",
        "    processing = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', activation='relu')(processing)\n",
        "    processing = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', activation='relu')(processing)\n",
        "    processing = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', activation='relu')(processing)\n",
        "    processing = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', activation='relu')(processing)\n",
        "    processing = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', activation='relu')(processing)\n",
        "    processing = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', activation='relu')(processing)\n",
        "    processing = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', activation='relu')(processing)\n",
        "    processing = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', activation='relu')(processing)\n",
        "    processing = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', activation='relu')(processing)\n",
        "    processing = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', activation='relu')(processing)\n",
        "    processing = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', activation='relu')(processing)\n",
        "    processing = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', activation='relu')(processing)\n",
        "    processing = Conv2D(1, (3, 3), padding='same', kernel_initializer='he_normal')(processing)\n",
        "    Residual = processing\n",
        "\n",
        "    high_resolution_image = Add() ([low_resolution_image, Residual])\n",
        "    \n",
        "    model = Model(low_resolution_image, high_resolution_image)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#conexion a google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqIesnHNuSV6",
        "outputId": "03bff0ae-0531-4de6-e486-e3aa45952456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interactive = True\n",
        "filename = '/content/drive/MyDrive/ColabNotebooks/Data/TENSOR_2x2x2.nii' \n",
        "#se cargan las imagenes\n",
        "img = nib.load(filename)\n",
        "data = img.get_fdata()\n",
        "#se obtiene el numero ttotal de imagenes\n",
        "num_img = data.shape[3]*data.shape[2]\n",
        "\n",
        "#se reduce la dimension de las imagenes\n",
        "data = data.reshape(256,256,-1)\n",
        "#se normalizan las imgenes\n",
        "dataMax= data.max()\n",
        "data = data/dataMax\n"
      ],
      "metadata": {
        "id": "amzgFTUQuw46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#se reduce la resolucion de las imagenes\n",
        "scale = 2\n",
        "dataLow=data[0:data.shape[0]:scale,0:data.shape[1]:scale,:]\n",
        "dataLowR = tf.image.resize(dataLow, [256, 256], method='bicubic')\n",
        "dataLowR=np.array(dataLowR)\n",
        "print(\"LowRes Data resized\",dataLowR.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3cVwBnvamUE",
        "outputId": "511a21de-bb30-4067-d362-6bd54f7a3540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LowRes Data resized (256, 256, 858)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#se transponen los ejes y se agrega una dismension extra porque es el formato que recibe la red\n",
        "dataLowR,data = dataLowR.transpose(2,0,1),data.transpose(2,0,1)\n",
        "dataLowR,data =dataLowR.reshape(-1,dataLowR.shape[1],dataLowR.shape[2],1),data.reshape(-1,data.shape[1],data.shape[2],1)\n",
        "print(\"data shape:\",data.shape)\n",
        "print(\"datalowR shape:\",dataLowR.shape)\n",
        "#Se hace la separacion de datos es training y test teniendo una separacion de 85% y 15% respectivamente\n",
        "trainX,testX,trainY,testY = train_test_split(dataLowR,data,test_size = 0.15,random_state = 2024)\n",
        "print(\"TrainX shape:\",trainX.shape)\n",
        "print(\"TrainY shape:\",trainY.shape)"
      ],
      "metadata": {
        "id": "zUaYvCinvG86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c802ccc9-ad97-43e6-d06b-651b4153b210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data shape: (858, 256, 256, 1)\n",
            "datalowR shape: (858, 256, 256, 1)\n",
            "TrainX shape: (729, 256, 256, 1)\n",
            "TrainY shape: (729, 256, 256, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creacion, compilacion y entrenamiento del modelo\n",
        "model = VDSR_origin(input_shape=(256, 256, 1))\n",
        "opt = Adam(lr=3E-3, decay=1E-3)\n",
        "model.compile(loss='mse', optimizer=opt, metrics=[losses.mse])\n",
        "\n",
        "# Registro de tiempo de inicio\n",
        "tiempo_inicio = time.time()\n",
        "EPOCHS = 500\n",
        "model_train = model.fit(trainX,trainY, batch_size=32, epochs=EPOCHS, validation_split=0.177)\n",
        "# Registro de tiempo de finalización\n",
        "tiempo_fin = time.time()\n",
        "\n",
        "#grafica epocas vs Training loss y validation loss\n",
        "loss = model_train.history['loss']\n",
        "val_loss = model_train.history['val_loss']\n",
        "epochs = range(EPOCHS)\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# Cálculo del tiempo total de ejecución y salida del resultado\n",
        "tiempo_total = tiempo_fin - tiempo_inicio\n",
        "print(\"Tiempo total de ejecución: \", tiempo_total, \" segundos\")#Tiempo total de ejecución:  50996.75665998459  segundos\n",
        "\n",
        "model.save('modelVDSR500epochs.keras')\n",
        "files.download(\"modelVDSR500epochs.keras\")\n"
      ],
      "metadata": {
        "id": "Ezqwi5HjuLGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#metricas\n",
        "def psnr(imagenesGT, imagenesPred):\n",
        "  psnrGlobal = []\n",
        "  for i in range(len(imagenesGT)):\n",
        "    psnr = cv2.PSNR(imagenesGT[i], imagenesPred[i])\n",
        "    psnrGlobal.append(psnr)\n",
        "  psnrGlobal = np.array(psnrGlobal)\n",
        "  return (psnrGlobal.mean(),psnrGlobal.std())\n",
        "\n",
        "\n",
        "def rmse(imagenesGT, imagenesPred):\n",
        "  rmseGlobal = []\n",
        "  for i in range(len(imagenesGT)):\n",
        "    rmse = np.sqrt(np.mean((imagenesGT[i] - imagenesPred[i])**2))\n",
        "    rmseGlobal.append(rmse)\n",
        "  rmseGlobal = np.array(rmseGlobal)\n",
        "  return (rmseGlobal.mean(),rmseGlobal.std())\n",
        "\n",
        "def mse(imagenesGT, imagenesPred):\n",
        "  mseGlobal = []\n",
        "  for i in range(len(imagenesGT)):\n",
        "    mse = np.mean((imagenesGT[i] - imagenesPred[i])**2)\n",
        "    mseGlobal.append(mse)\n",
        "  mseGlobal = np.array(mseGlobal)\n",
        "  return (mseGlobal.mean(),mseGlobal.std())\n",
        "\n",
        "def ssim_(imagenesGT, imagenesPred):\n",
        "  ssimGlobal = []\n",
        "  for i in range(len(imagenesGT)):\n",
        "    ssim_index = ssim(imagenesGT[i], imagenesPred[i], data_range=imagenesPred[i].max() - imagenesPred[i].min(), multichannel=True)\n",
        "    ssimGlobal.append(ssim_index)\n",
        "  ssimGlobal = np.array(ssimGlobal)\n",
        "  return (ssimGlobal.mean(),ssimGlobal.std())\n"
      ],
      "metadata": {
        "id": "gaDyyNYBYVP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#carga del modelo entrenado\n",
        "#model = load_model('/content/drive/MyDrive/Tesis/modelVDSR500epochs.h5')"
      ],
      "metadata": {
        "id": "Jk8C8vqMUHvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#se definen las funciones de mascara\n",
        "def create_mask(img):\n",
        "  img = np.array(img)\n",
        "  plt.imshow(img,cmap=\"gray\")\n",
        "  plt.show()\n",
        "  print(img.dtype)\n",
        "  img2 = img*255\n",
        "  # Convertir la imagen a escala de grises\n",
        "  gray = img2.astype(\"uint8\")\n",
        "  plt.imshow(gray,cmap=\"gray\")\n",
        "  plt.show()\n",
        "  # Calcular el umbral Otsu para la imagen en escala de grises\n",
        "  _,thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "  plt.imshow(thresh,cmap=\"gray\")\n",
        "  plt.show()\n",
        " \n",
        "\n",
        "  # Encontrar los contornos de la imagen binaria\n",
        "  contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  # Encontrar el contorno más grande\n",
        "  max_contour = max(contours, key=cv2.contourArea)\n",
        "  # Crear una imagen negra del mismo tamaño que la original\n",
        "  mask = np.zeros_like(gray)\n",
        "\n",
        "  # Dibujar el contorno más grande en blanco en la imagen negra\n",
        "  cv2.drawContours(mask, [max_contour], 0, (255), -1)\n",
        "\n",
        "  # Dilatar la máscara para ampliar el área de recorte\n",
        "  kernel = np.ones((15, 15), np.uint8)\n",
        "  mask = cv2.dilate(mask, kernel, iterations=1)\n",
        "\n",
        "  return mask\n",
        "\n",
        "\n",
        "def cut(img, mask):\n",
        "  # Convertir la imagen a escala de grises\n",
        "  gray = img.astype(\"uint8\")\n",
        "  # Aplicar la máscara a la imagen original\n",
        "  masked_img = cv2.bitwise_and(img, img, mask=mask)\n",
        "\n",
        "  return masked_img\n",
        "\n",
        "def recortarSet(imagenes, mask):\n",
        "  imagenes_recortadas = []\n",
        "  for i in imagenes:\n",
        "    imagenes_recortadas.append(cut(i, mask))\n",
        "  return imagenes_recortadas"
      ],
      "metadata": {
        "id": "VaHV-psYurJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prediccion y recorte del conjunto de test\n",
        "data = np.array(data)\n",
        "\n",
        "ypred = model.predict(testX)\n",
        "data = data.astype(np.float32)\n",
        "testY = testY.astype(np.float32)\n",
        "\n",
        "\n",
        "mask = create_mask(data[480])\n",
        "data_cut = np.array(recortarSet(data, mask))\n",
        "ypred_cut = np.array(recortarSet(ypred, mask))\n",
        "testY_cut = np.array(recortarSet(testY, mask))\n",
        "dataLowR_cut = np.array(recortarSet(dataLowR, mask))"
      ],
      "metadata": {
        "id": "eEtcFmncuvrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Metricas sin recorte\")\n",
        "valssim,stdssim = ssim_(testY, ypred)\n",
        "print('SSIM:', valssim, \"standard deviation: \", stdssim)\n",
        "valmse,stdmse = mse(testY, ypred)\n",
        "print('MSE:', valmse, \"standard deviation: \", stdmse)\n",
        "valrmse,stdrmse = rmse(testY, ypred)\n",
        "print('RMSE:', valrmse, \"standard deviation: \", stdrmse)\n",
        "valpsnr,stdpsnr = psnr(testY, ypred)\n",
        "print('PSNR:', valpsnr, \"standard deviation: \", stdpsnr)\n",
        "\n",
        "print(\"Metricas con recorte\")\n",
        "valssim,stdssim = ssim_(testY_cut, ypred_cut)\n",
        "print('SSIM:', valssim, \"standard deviation: \", stdssim)\n",
        "valmse,stdmse = mse(testY_cut, ypred_cut)\n",
        "print('MSE:', valmse, \"standard deviation: \", stdmse)\n",
        "valrmse,stdrmse = rmse(testY_cut, ypred_cut)\n",
        "print('RMSE:', valrmse, \"standard deviation: \", stdrmse)\n",
        "valpsnr,stdpsnr = psnr(testY_cut, ypred_cut)\n",
        "print('PSNR:', valpsnr, \"standard deviation: \", stdpsnr)"
      ],
      "metadata": {
        "id": "_K0w3lpEfmdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backTo4D(img):\n",
        "  \"\"\"\n",
        "  Funcion que dado un conjunto de imagnes con dimensiones (858,256,256)\n",
        "  lo convierte a (256,256,33,26)\n",
        "  \"\"\"\n",
        "  nimg =  img.reshape(858,256,256)\n",
        "  nimg = nimg.transpose(1,2,0)\n",
        "  nimg = nimg.reshape(256,256,33,26)\n",
        "  return nimg"
      ],
      "metadata": {
        "id": "x1WDvaHswQEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#se leen los valores propios y vectores propios de los tensores\n",
        "bvals, bvecs = read_bvals_bvecs('/content/drive/MyDrive/ColabNotebooks/Data/TENSOR_2x2x2.bval', '/content/drive/MyDrive/ColabNotebooks/Data/TENSOR_2x2x2.bvec')\n",
        "\n",
        "data_cut4 = backTo4D(data_cut)\n",
        "gtab = gradient_table(bvals, bvecs)\n",
        "tensorm = dti.TensorModel(gtab)\n",
        "tenfitdata = tensorm.fit(data_cut4)"
      ],
      "metadata": {
        "id": "zGsg9l54wWyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataLowpred = model.predict(dataLowR)\n",
        "dataLow_cut = np.array(recortarSet(dataLowpred, mask))\n",
        "\n",
        "dataLow4 = backTo4D(dataLow_cut)\n",
        "gtab = gradient_table(bvals, bvecs)\n",
        "tensorm = dti.TensorModel(gtab)\n",
        "tenfitdatalow = tensorm.fit(dataLow4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNj_axgZwXwW",
        "outputId": "5d1d3097-e486-43c9-d06b-405b7f673a79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 16s 613ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#se calcula la metrica de norma de frobenius\n",
        "fnorm = dti.norm(tenfitdata.quadratic_form - tenfitdatalow.quadratic_form)\n",
        "print(\"mean: \",fnorm.mean(), \" std: \", fnorm.std())"
      ],
      "metadata": {
        "id": "9JCoCnX-wZ7Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4ea41f1-3160-4bb1-80c8-b63175fdd8fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean:  0.00015885129904424965  std:  0.0003825490417568843\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#se calcula la metrica de MSE de FA\n",
        "FAdata = tenfitdata.fa.transpose(2,0,1)\n",
        "FApred = tenfitdatalow.fa.transpose(2,0,1)\n",
        "valfa,stdfa = mse(FAdata, FApred)\n",
        "print('MSE de FA:', valfa, \"standard deviation: \", stdfa)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmtB5COmipLq",
        "outputId": "d7e46b3d-4608-4208-aa8e-208c8791de1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256, 256, 33)\n",
            "MSE de FA: 0.01552567431065916 standard deviation:  0.009817935583266775\n"
          ]
        }
      ]
    }
  ]
}